name: Web Scraping

on:
  push:
    branches: [master]
  pull_request:
    branches: [master]
  schedule:
    - cron: "0 */12 * * *" # Runs every 12 hours
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: 3.11

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt  # Make sure to create requirements.txt if you have dependencies

      - name: Run the script
        run: |
          python scraper.py

      # - name: Rename and upload JSON artifact
      #   run: |
      #     mv -f news.json data/news.json
      #     echo "File renamed and ready for upload"

      - name: Upload JSON artifact
        uses: actions/upload-artifact@v4
        with:
          name: news
          path: ./news.json

      - name: Debug Workspace
        run: |
          echo "Workspace: $GITHUB_WORKSPACE"

      - name: Debug File Existence
        run: |
          ls -R $GITHUB_WORKSPACE
          echo "File exists: $(test -e $GITHUB_WORKSPACE/news.json && echo true || echo false)"
