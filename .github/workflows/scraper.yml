name: Web Scraping

on:
  schedule:
    - cron: '0 */12 * * *'  # Runs every 12 hours
  workflow_dispatch:  # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.8

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt  # Make sure to create requirements.txt if you have dependencies

    - name: Run the script
      run: |
        python scraper.py
        cp -f news.json $GITHUB_WORKSPACE/news.json  # Overwrite the existing news.json file
        rm news.json  # Remove the original news.json file

    - name: Upload JSON artifact
      uses: actions/upload-artifact@v2
      with:
        name: news
        path: news.json
